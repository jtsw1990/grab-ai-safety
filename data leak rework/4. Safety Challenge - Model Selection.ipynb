{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "- The main reason for this is that GBMs has no good way to introduce sample weights\n",
    "- To add GBMs with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:41:35.560672Z",
     "start_time": "2019-06-14T15:41:34.320195Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dill as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the relevant pieces\n",
    "- X_train, X_test, y_train, y_test\n",
    "- Feature transformer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:41:36.325338Z",
     "start_time": "2019-06-14T15:41:35.562641Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(\"../../grab-ai-safety-data/X_train_transformed.pickle\")\n",
    "X_test = pd.read_pickle(\"../../grab-ai-safety-data/X_test.pickle\")\n",
    "y_test = pd.read_pickle(\"../../grab-ai-safety-data/y_test.pickle\")\n",
    "y_train = pd.read_pickle(\"../../grab-ai-safety-data/y_train.pickle\")\n",
    "\n",
    "clean_columns = pickle.load(open(\"../outputs/clean_columns.pickle\", \"rb\"))\n",
    "create_windows = pickle.load(open(\"../outputs/create_windows.pickle\", \"rb\"))\n",
    "extract_features = pickle.load(open(\"../outputs/extract_features.pickle\", \"rb\"))\n",
    "min_boundary = pickle.load(open(\"../outputs/min_boundary.pickle\", \"rb\"))\n",
    "max_boundary = pickle.load(open(\"../outputs/max_boundary.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply transformations to test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:41:43.379788Z",
     "start_time": "2019-06-14T15:41:36.327361Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = (\n",
    "    X_test.pipe(\n",
    "        clean_columns\n",
    "    ).pipe(\n",
    "        create_windows\n",
    "    ).pipe(\n",
    "        extract_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:41:43.705280Z",
     "start_time": "2019-06-14T15:41:43.381846Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.drop_duplicates(\n",
    "    subset=\"bookingID\", \n",
    "    keep=\"first\"\n",
    ").set_index(\"bookingID\")[\"label\"]\n",
    "y_test = y_test.drop_duplicates(\n",
    "    subset=\"bookingID\", \n",
    "    keep=\"first\"\n",
    ").set_index(\"bookingID\")[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling data\n",
    "- Find a way to take care of class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:41:43.740720Z",
     "start_time": "2019-06-14T15:41:43.707069Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped = pd.concat([X_train, y_train], axis=1)\n",
    "df_majority = df_grouped[df_grouped[\"label\"] == 0]\n",
    "df_minority = df_grouped[df_grouped[\"label\"] == 1]\n",
    "\n",
    "df_minority_upsampled = resample(\n",
    "    df_minority,\n",
    "    replace=True,\n",
    "    n_samples=df_majority.count()[0],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_grouped = pd.concat(\n",
    "    [df_majority, df_minority_upsampled]\n",
    ")\n",
    "\n",
    "X_train = df_grouped.iloc[:, :-1]\n",
    "y_train = df_grouped.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipelines\n",
    "- Define pipelines\n",
    "    - GBM\n",
    "    - Logisitc Regresion\n",
    "    - Logistic Regression with PCA\n",
    "    - Random Forests\n",
    "    - Random Forests with PCA\n",
    "- Define GS grids\n",
    "- To add in grid search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:41:43.747594Z",
     "start_time": "2019-06-14T15:41:43.742364Z"
    }
   },
   "outputs": [],
   "source": [
    "jobs = -1\n",
    "pipe_gbm = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", GradientBoostingClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_lr = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\", \n",
    "            random_state=42, \n",
    "            penalty=\"l2\", \n",
    "            max_iter=4000)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_lr_pca = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"lbfgs\", \n",
    "            random_state=42, \n",
    "            penalty=\"l2\",\n",
    "            max_iter=4000\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_rf = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            random_state=42, \n",
    "            class_weight=None)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_rf_pca = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            random_state=42, \n",
    "            class_weight=None))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:41:43.752523Z",
     "start_time": "2019-06-14T15:41:43.749281Z"
    }
   },
   "outputs": [],
   "source": [
    "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range_fl = [1.0, 0.5, 0.1]\n",
    "\n",
    "grid_params_gbm = [\n",
    "    {}\n",
    "    ]\n",
    "\n",
    "grid_params_lr = [\n",
    "    {}\n",
    "] \n",
    "\n",
    "grid_params_rf = { \n",
    "    \"clf__n_estimators\" : [100],\n",
    "    \"clf__max_features\" : [5, 6, 7, 8, 9, 10]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T15:41:43.759099Z",
     "start_time": "2019-06-14T15:41:43.754697Z"
    }
   },
   "outputs": [],
   "source": [
    "gs_gbm = GridSearchCV(\n",
    "    estimator=pipe_gbm,\n",
    "    param_grid=grid_params_gbm,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10,\n",
    "    n_jobs=jobs\n",
    ")\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=grid_params_lr,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10\n",
    ") \n",
    "\n",
    "gs_lr_pca = GridSearchCV(\n",
    "    estimator=pipe_lr_pca,\n",
    "    param_grid=grid_params_lr,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=grid_params_rf,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10, \n",
    "    n_jobs=jobs\n",
    ")\n",
    "\n",
    "gs_rf_pca = GridSearchCV(\n",
    "    estimator=pipe_rf_pca,\n",
    "    param_grid=grid_params_rf,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10, \n",
    "    n_jobs=jobs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-14T15:41:34.319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Gradient Boosted Machine\n",
      "Best params: {}\n",
      "Best training accuracy: 0.758\n",
      "Test set accuracy score for best params: 0.688 \n",
      "\n",
      "Estimator: Logistic Regression\n",
      "Best params: {}\n",
      "Best training accuracy: 0.653\n",
      "Test set accuracy score for best params: 0.592 \n",
      "\n",
      "Estimator: Logistic Regression w/PCA\n",
      "Best params: {}\n",
      "Best training accuracy: 0.568\n",
      "Test set accuracy score for best params: 0.673 \n",
      "\n",
      "Estimator: Random Forest\n"
     ]
    }
   ],
   "source": [
    "grids = [\n",
    "    gs_gbm, \n",
    "    gs_lr, \n",
    "    gs_lr_pca, \n",
    "    gs_rf, \n",
    "    gs_rf_pca\n",
    "]\n",
    "\n",
    "grid_dict = {\n",
    "    0: \"Gradient Boosted Machine\",\n",
    "    1: \"Logistic Regression\", \n",
    "    2: \"Logistic Regression w/PCA\", \n",
    "    3: \"Random Forest\", \n",
    "    4: \"Random Forest w/PCA\", \n",
    "}\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\n",
    "    # Fit grid search\n",
    "    gs.fit(X_train, y_train)\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-14T15:41:34.322Z"
    }
   },
   "outputs": [],
   "source": [
    "color_dict = {\n",
    "    0: \"blue\",\n",
    "    1: \"red\", \n",
    "    2: \"green\", \n",
    "    3: \"black\", \n",
    "    4: \"purple\", \n",
    "}\n",
    "plt.figure(figsize=(20, 15))\n",
    "for idx, gs in enumerate(grids):\n",
    "    probs = gs.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(\n",
    "        fpr, \n",
    "        tpr, \n",
    "        color=color_dict[idx], \n",
    "        label = '%s AUC = %0.2f' % (grid_dict[idx], roc_auc)\n",
    "    )\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-14T15:41:34.326Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\").fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.DataFrame(\n",
    "    rf.feature_importances_,\n",
    "    index = X_train.columns,\n",
    "    columns=['importance']\n",
    ").sort_values(\n",
    "    'importance', \n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-14T15:41:34.329Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(feature_importances.index, feature_importances[\"importance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "- Check if there is data leakage?\n",
    "- A sudden jump to 90% accuracy seems dubious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-14T15:41:34.331Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "cross_val_score(\n",
    "    pipe_rf, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=cv\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
