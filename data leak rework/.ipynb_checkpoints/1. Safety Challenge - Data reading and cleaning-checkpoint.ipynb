{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extract zip from web\n",
    "\n",
    "- Specifies the source link, destination url and file name to download and extract data files\n",
    "- Currently reading from external folder as github does not support large files\n",
    "    - To rerun function for testing before submission\n",
    "    - To add checks and conditions for the function\n",
    "- Link to zip download here: \"https://s3-ap-southeast-1.amazonaws.com/grab-aiforsea-dataset/safety.zip\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE = \"https://s3-ap-southeast-1.amazonaws.com/grab-aiforsea-dataset/safety.zip\"\n",
    "OUTPUT_PATH = \"/Users/jiayihuang/Desktop/Jtsw/grab-ai-safety/data\"\n",
    "FILE_NAME = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownloadProgressBar(tqdm):\n",
    "    '''Class for tqdm progress bar.'''\n",
    "    def update_to(self, b=1, bsize=1, tsize=None):\n",
    "        if tsize is not None:\n",
    "            self.total = tsize\n",
    "        self.update(b * bsize - self.n)\n",
    "\n",
    "\n",
    "def maybe_download(url, output_path, dest_file_name):\n",
    "    '''Function that checks the validity of a desired URL,\n",
    "    downloads and extracts a ZIP file for the purposes of\n",
    "    the Grab AI challenge.\n",
    "    \n",
    "    Args:\n",
    "    url (str): Download path of the dataset in question\n",
    "    output_path(str): path of the desired download destination\n",
    "    dest_file_name(str): Desired file name. \n",
    "    To include .zip extension\n",
    "    \n",
    "    Returns:\n",
    "    None.\n",
    "    Extracts all relevant data files into a desired folder for\n",
    "    download.\n",
    "    '''\n",
    "    full_path = output_path+'/'+dest_file_name\n",
    "    with DownloadProgressBar(\n",
    "        unit='B', \n",
    "        unit_scale=True,\n",
    "        miniters=1, \n",
    "        desc=url.split(\"/\")[-1]\n",
    "    ) as t:\n",
    "        urllib.request.urlretrieve(\n",
    "            url, \n",
    "            filename=full_path, \n",
    "            reporthook=t.update_to\n",
    "        )\n",
    "    with zipfile.ZipFile(full_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download_url(SOURCE, OUTPUT_PATH, FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T03:07:47.763230Z",
     "start_time": "2019-06-11T03:07:19.061720Z"
    }
   },
   "outputs": [],
   "source": [
    "df0 = pd.read_csv(\"../grab-ai-safety-data/features/part-00000-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\")\n",
    "df1 = pd.read_csv(\"../grab-ai-safety-data/features/part-00001-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\")\n",
    "df2 = pd.read_csv(\"../grab-ai-safety-data/features/part-00002-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\")\n",
    "df3 = pd.read_csv(\"../grab-ai-safety-data/features/part-00003-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\")\n",
    "df4 = pd.read_csv(\"../grab-ai-safety-data/features/part-00004-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\")\n",
    "df5 = pd.read_csv(\"../grab-ai-safety-data/features/part-00005-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\")\n",
    "df6 = pd.read_csv(\"../grab-ai-safety-data/features/part-00006-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\")\n",
    "df7 = pd.read_csv(\"../grab-ai-safety-data/features/part-00007-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\")\n",
    "df8 = pd.read_csv(\"../grab-ai-safety-data/features/part-00008-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\")\n",
    "df9 = pd.read_csv(\"../grab-ai-safety-data/features/part-00009-e6120af0-10c2-4248-97c4-81baf4304e5c-c000.csv\")\n",
    "response = pd.read_csv(\"../grab-ai-safety-data/labels/part-00000-e9445087-aa0a-433b-a7f6-7f4c19d78ad6-c000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and format data\n",
    "- Join the feautres together with the labels\n",
    "- Get rid of the 18 duplicated label entries\n",
    "- Get rid of the 5 entries with ridiculous trip durations. If max second is the last record taken for each trip then it should represent the duration of the trip.\n",
    "    - 5 trips showed durations of over 47 years?\n",
    "    - 2.2 hour trip is the threshold for sensible. Caught in a jam maybe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T03:07:48.680490Z",
     "start_time": "2019-06-11T03:07:47.992682Z"
    }
   },
   "outputs": [],
   "source": [
    "df_features = pd.concat(\n",
    "    [df1, df2, df3, df4, df5, df6, df7, df8, df9], \n",
    "    axis=0\n",
    ").drop_duplicates(\n",
    "    keep=False\n",
    ")\n",
    "response = response.drop_duplicates(subset=\"bookingID\", keep=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T03:12:28.111774Z",
     "start_time": "2019-06-11T03:12:14.508575Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.merge(\n",
    "    df_features,\n",
    "    response,\n",
    "    how=\"inner\",\n",
    "    on=\"bookingID\"\n",
    ").sort_values(\n",
    "    [\"bookingID\", \"second\"],\n",
    "    ascending=True\n",
    ")\n",
    "\n",
    "df.columns = [x.lower() for x in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T02:54:37.716682Z",
     "start_time": "2019-06-11T02:54:33.833620Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('../grab-ai-safety-data/df_full.pickle', 'wb') as f:\n",
    "    pickle.dump(df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
