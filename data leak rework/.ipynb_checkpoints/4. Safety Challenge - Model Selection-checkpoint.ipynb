{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "- No good way to introduce sample weights for GBM with sklearn wrapper\n",
    "- To add GBMs with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T06:57:28.891961Z",
     "start_time": "2019-06-15T06:57:27.600247Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dill as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.utils import resample\n",
    "from sklearn.externals import joblib\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the relevant pieces\n",
    "- X_train, X_test, y_train, y_test\n",
    "- Feature transformer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T06:57:29.636185Z",
     "start_time": "2019-06-15T06:57:28.894371Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(\"../../grab-ai-safety-data/X_train_transformed.pickle\")\n",
    "X_test = pd.read_pickle(\"../../grab-ai-safety-data/X_test.pickle\")\n",
    "y_test = pd.read_pickle(\"../../grab-ai-safety-data/y_test.pickle\")\n",
    "y_train = pd.read_pickle(\"../../grab-ai-safety-data/y_train.pickle\")\n",
    "\n",
    "clean_columns = pickle.load(open(\"../outputs/clean_columns.pickle\", \"rb\"))\n",
    "create_windows = pickle.load(open(\"../outputs/create_windows.pickle\", \"rb\"))\n",
    "extract_features = pickle.load(open(\"../outputs/extract_features.pickle\", \"rb\"))\n",
    "min_boundary = pickle.load(open(\"../outputs/min_boundary.pickle\", \"rb\"))\n",
    "max_boundary = pickle.load(open(\"../outputs/max_boundary.pickle\", \"rb\"))\n",
    "min_speed = pickle.load(open(\"../outputs/min_speed.pickle\", \"rb\"))\n",
    "max_speed = pickle.load(open(\"../outputs/max_speed.pickle\", \"rb\"))\n",
    "min_accuracy = pickle.load(open(\"../outputs/min_accuracy.pickle\", \"rb\"))\n",
    "max_accuracy = pickle.load(open(\"../outputs/max_accuracy.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T06:57:29.970945Z",
     "start_time": "2019-06-15T06:57:29.638113Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = y_train.drop_duplicates(subset=\"bookingID\", keep=\"first\").set_index(\"bookingID\")\n",
    "y_test = y_test.drop_duplicates(subset=\"bookingID\", keep=\"first\").set_index(\"bookingID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply transformations to test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T06:57:37.139253Z",
     "start_time": "2019-06-15T06:57:29.972867Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = (\n",
    "    X_test.pipe(\n",
    "        clean_columns\n",
    "    ).pipe(\n",
    "        create_windows\n",
    "    ).pipe(\n",
    "        extract_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T06:57:37.149456Z",
     "start_time": "2019-06-15T06:57:37.141192Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.merge(\n",
    "    X_train, \n",
    "    pd.DataFrame(y_train), \n",
    "    how=\"left\", \n",
    "    left_index=True, \n",
    "    right_index=True\n",
    ")[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T06:57:37.156335Z",
     "start_time": "2019-06-15T06:57:37.151290Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.merge(\n",
    "    X_test,\n",
    "    pd.DataFrame(y_test),\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling data\n",
    "- Find a way to take care of class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T06:57:37.178984Z",
     "start_time": "2019-06-15T06:57:37.157799Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped = pd.concat([X_train, y_train], axis=1)\n",
    "df_majority = df_grouped[df_grouped[\"label\"] == 0]\n",
    "df_minority = df_grouped[df_grouped[\"label\"] == 1]\n",
    "\n",
    "df_minority_upsampled = resample(\n",
    "    df_minority,\n",
    "    replace=True,\n",
    "    n_samples=df_majority.count()[0],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_grouped = pd.concat(\n",
    "    [df_majority, df_minority_upsampled]\n",
    ")\n",
    "\n",
    "X_train = df_grouped.iloc[:, :-1]\n",
    "y_train = df_grouped.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipelines\n",
    "- Define pipelines\n",
    "    - GBM\n",
    "    - Logisitc Regresion\n",
    "    - Logistic Regression with PCA\n",
    "    - Random Forests\n",
    "    - Random Forests with PCA\n",
    "- Define GS grids\n",
    "- To add in grid search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T06:57:37.190076Z",
     "start_time": "2019-06-15T06:57:37.181454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pipe_rf_pca = Pipeline(\\n    [\\n        (\"scl\", StandardScaler()),\\n        (\"pca\", PCA(n_components=2)),\\n        (\"clf\", RandomForestClassifier(\\n            random_state=42, \\n            class_weight=\"balanced\"))\\n    ]\\n)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs = -1\n",
    "\n",
    "pipe_gbm = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", GradientBoostingClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_lr = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            random_state=42, \n",
    "            penalty=\"l2\", \n",
    "            max_iter=4000)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "'''pipe_lr_pca = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", LogisticRegression( \n",
    "            random_state=42, \n",
    "            penalty=\"l2\",\n",
    "            max_iter=4000\n",
    "        ))\n",
    "    ]\n",
    ")'''\n",
    "\n",
    "pipe_rf = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            random_state=42, \n",
    "            class_weight=\"balanced\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "'''pipe_rf_pca = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            random_state=42, \n",
    "            class_weight=\"balanced\"))\n",
    "    ]\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T06:57:37.195412Z",
     "start_time": "2019-06-15T06:57:37.191801Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_params_gbm = [\n",
    "    {\n",
    "        \"clf__learning_rate\": [0.1],\n",
    "        #\"clf__min_samples_split\": np.linspace(0.1, 0.5, 2),\n",
    "        #\"clf__min_samples_leaf\": np.linspace(0.1, 0.5, 2),\n",
    "        \"clf__max_depth\":[8],\n",
    "        \"clf__max_features\":[\"log2\"],\n",
    "        \"clf__n_estimators\":[100]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_params_lr = [\n",
    "   {\n",
    "        \"clf__solver\" : [\"lbfgs\", \"sag\", \"saga\"],\n",
    "        \"clf__C\" : np.logspace(-3,3,7),\n",
    "   }\n",
    "]\n",
    "\n",
    "grid_params_rf = [\n",
    "    { \n",
    "        \"clf__n_estimators\" : [100],\n",
    "        \"clf__max_features\" : [0.5, 0.75],\n",
    "        \"clf__max_depth\" : [8]\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-15T06:57:37.203860Z",
     "start_time": "2019-06-15T06:57:37.197803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gs_rf_pca = GridSearchCV(\\n    estimator=pipe_rf_pca,\\n    param_grid=grid_params_rf,\\n    scoring=\"roc_auc\",\\n    cv=10, \\n    n_jobs=jobs\\n)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_gbm = GridSearchCV(\n",
    "    estimator=pipe_gbm,\n",
    "    param_grid=grid_params_gbm,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10,\n",
    "    n_jobs=jobs\n",
    ")\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=grid_params_lr,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10\n",
    ") \n",
    "\n",
    "'''gs_lr_pca = GridSearchCV(\n",
    "    estimator=pipe_lr_pca,\n",
    "    param_grid=grid_params_lr,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10\n",
    ")'''\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=grid_params_rf,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10, \n",
    "    n_jobs=jobs\n",
    ")\n",
    "\n",
    "'''gs_rf_pca = GridSearchCV(\n",
    "    estimator=pipe_rf_pca,\n",
    "    param_grid=grid_params_rf,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10, \n",
    "    n_jobs=jobs\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-15T06:57:27.601Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Gradient Boosted Machine\n",
      "Best params: {'clf__learning_rate': 0.1, 'clf__max_depth': 8, 'clf__max_features': 'log2', 'clf__n_estimators': 100}\n",
      "Best training accuracy: 0.929\n",
      "Test set accuracy score for best params: 0.730 \n",
      "ROC_AUC score for best params: 0.709\n",
      "\n",
      "Estimator: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "grids = [\n",
    "    gs_gbm, \n",
    "    gs_lr, \n",
    "    # gs_lr_pca, \n",
    "    gs_rf, \n",
    "    # gs_rf_pca\n",
    "]\n",
    "\n",
    "grid_dict = {\n",
    "    0: \"Gradient Boosted Machine\",\n",
    "    1: \"Logistic Regression\", \n",
    "    # 2: \"Logistic Regression w/PCA\", \n",
    "    2: \"Random Forest\", \n",
    "    # 4: \"Random Forest w/PCA\", \n",
    "}\n",
    "\n",
    "# Fit the grid search objects\n",
    "print(\"Performing model optimizations...\")\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print(\"\\nEstimator: %s\" % grid_dict[idx])\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best params: %s\" % gs.best_params_)\n",
    "    print(\"Best training accuracy: %.3f\" % gs.best_score_)\n",
    "\n",
    "    y_pred = gs.predict(X_test)\n",
    "    y_prob = gs.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"Test set accuracy score for best params: %.3f \" % accuracy_score(y_test, y_pred))\n",
    "    print(\"ROC_AUC score for best params: %.3f\" % roc_auc_score(y_test, y_prob))\n",
    "\n",
    "    if roc_auc_score(y_test, y_prob) > best_acc:\n",
    "        best_acc = roc_auc_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print(\"\\nClassifier with best test set accuracy: %s\" % grid_dict[best_clf])\n",
    "joblib.dump(gs, \"../outputs/{}.pkl\".format(str(grid_dict[best_clf]) + \"_\" + str(best_acc))\n",
    "print(\"\\n%s has been exported to outputs/best_classifier.pkl\" % grid_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-15T06:57:27.602Z"
    }
   },
   "outputs": [],
   "source": [
    "color_dict = {\n",
    "    0: \"blue\",\n",
    "    1: \"red\", \n",
    "    2: \"green\", \n",
    "    3: \"black\", \n",
    "    4: \"purple\", \n",
    "}\n",
    "plt.figure(figsize=(20, 15))\n",
    "for idx, gs in enumerate(grids):\n",
    "    probs = gs.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.title(\"Receiver Operating Characteristic\")\n",
    "    plt.plot(\n",
    "        fpr, \n",
    "        tpr, \n",
    "        color=color_dict[idx], \n",
    "        label = \"%s AUC = %0.2f\" % (grid_dict[idx], roc_auc)\n",
    "    )\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.plot([0, 1], [0, 1], \"r--\")\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-15T06:57:27.604Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\").fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.DataFrame(\n",
    "    rf.feature_importances_,\n",
    "    index = X_train.columns,\n",
    "    columns=[\"importance\"]\n",
    ").sort_values(\n",
    "    \"importance\", \n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-15T06:57:27.605Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(feature_importances.index, feature_importances[\"importance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "- Check if there is data leakage?\n",
    "- A sudden jump to 90% accuracy seems dubious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-15T06:57:27.607Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "cross_val_score(\n",
    "    pipe_rf, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
