{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "- No good way to introduce sample weights for GBM with sklearn wrapper\n",
    "- To add GBMs with resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:40:02.679914Z",
     "start_time": "2019-06-14T17:40:00.929016Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dill as pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.utils import resample\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the relevant pieces\n",
    "- X_train, X_test, y_train, y_test\n",
    "- Feature transformer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:40:03.821496Z",
     "start_time": "2019-06-14T17:40:02.682055Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_pickle(\"../../grab-ai-safety-data/X_train_transformed.pickle\")\n",
    "X_test = pd.read_pickle(\"../../grab-ai-safety-data/X_test.pickle\")\n",
    "y_test = pd.read_pickle(\"../../grab-ai-safety-data/y_test.pickle\")\n",
    "y_train = pd.read_pickle(\"../../grab-ai-safety-data/y_train.pickle\")\n",
    "\n",
    "clean_columns = pickle.load(open(\"../outputs/clean_columns.pickle\", \"rb\"))\n",
    "create_windows = pickle.load(open(\"../outputs/create_windows.pickle\", \"rb\"))\n",
    "extract_features = pickle.load(open(\"../outputs/extract_features.pickle\", \"rb\"))\n",
    "min_boundary = pickle.load(open(\"../outputs/min_boundary.pickle\", \"rb\"))\n",
    "max_boundary = pickle.load(open(\"../outputs/max_boundary.pickle\", \"rb\"))\n",
    "min_speed = pickle.load(open(\"../outputs/min_speed.pickle\", \"rb\"))\n",
    "max_speed = pickle.load(open(\"../outputs/max_speed.pickle\", \"rb\"))\n",
    "min_accuracy = pickle.load(open(\"../outputs/min_accuracy.pickle\", \"rb\"))\n",
    "max_accuracy = pickle.load(open(\"../outputs/max_accuracy.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply transformations to test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:40:10.568250Z",
     "start_time": "2019-06-14T17:40:03.824215Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test = (\n",
    "    X_test.pipe(\n",
    "        clean_columns\n",
    "    ).pipe(\n",
    "        create_windows\n",
    "    ).pipe(\n",
    "        extract_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:40:10.923648Z",
     "start_time": "2019-06-14T17:40:10.570197Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train = pd.merge(\n",
    "    X_train, \n",
    "    pd.DataFrame(y_train), \n",
    "    how=\"left\", \n",
    "    left_index=True, \n",
    "    right_index=True\n",
    ")[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:40:10.923648Z",
     "start_time": "2019-06-14T17:40:10.570197Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test = pd.merge(\n",
    "    X_test,\n",
    "    pd.DataFrame(y_test),\n",
    "    how=\"left\",\n",
    "    left_index=True,\n",
    "    right_index=True\n",
    ")[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resampling data\n",
    "- Find a way to take care of class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:40:10.968517Z",
     "start_time": "2019-06-14T17:40:10.925687Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped = pd.concat([X_train, y_train], axis=1)\n",
    "df_majority = df_grouped[df_grouped[\"label\"] == 0]\n",
    "df_minority = df_grouped[df_grouped[\"label\"] == 1]\n",
    "\n",
    "df_minority_upsampled = resample(\n",
    "    df_minority,\n",
    "    replace=True,\n",
    "    n_samples=df_majority.count()[0],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "df_grouped = pd.concat(\n",
    "    [df_majority, df_minority_upsampled]\n",
    ")\n",
    "\n",
    "X_train = df_grouped.iloc[:, :-1]\n",
    "y_train = df_grouped.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Pipelines\n",
    "- Define pipelines\n",
    "    - GBM\n",
    "    - Logisitc Regresion\n",
    "    - Logistic Regression with PCA\n",
    "    - Random Forests\n",
    "    - Random Forests with PCA\n",
    "- Define GS grids\n",
    "- To add in grid search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:40:10.976971Z",
     "start_time": "2019-06-14T17:40:10.970396Z"
    }
   },
   "outputs": [],
   "source": [
    "jobs = -1\n",
    "pipe_gbm = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", GradientBoostingClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_lr = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            random_state=42, \n",
    "            penalty=\"l2\", \n",
    "            max_iter=4000)\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_lr_pca = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", LogisticRegression( \n",
    "            random_state=42, \n",
    "            penalty=\"l2\",\n",
    "            max_iter=4000\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_rf = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            random_state=42, \n",
    "            class_weight=\"balanced\")\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_rf_pca = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", RandomForestClassifier(\n",
    "            random_state=42, \n",
    "            class_weight=\"balanced\"))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:40:10.982730Z",
     "start_time": "2019-06-14T17:40:10.978783Z"
    }
   },
   "outputs": [],
   "source": [
    "grid_params_gbm = [\n",
    "    {\n",
    "        \"clf__learning_rate\": [0.1],\n",
    "        #\"clf__min_samples_split\": np.linspace(0.1, 0.5, 2),\n",
    "        #\"clf__min_samples_leaf\": np.linspace(0.1, 0.5, 2),\n",
    "        \"clf__max_depth\":[3,5,8],\n",
    "        \"clf__max_features\":[\"log2\",\"sqrt\"],\n",
    "        \"clf__n_estimators\":[100]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_params_lr = [\n",
    "   {\n",
    "       \"clf__solver\" : [\"lbfgs\", \"sag\", \"saga\"],\n",
    "        \"clf__C\" : np.logspace(-3,3,7),\n",
    "   }\n",
    "]\n",
    "\n",
    "grid_params_rf = { \n",
    "    \"clf__n_estimators\" : [50, 100],\n",
    "    \"clf__max_features\" : [0.5, 0.75],\n",
    "    \"clf__max_depth\" : [3, 5, 8]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:40:10.988407Z",
     "start_time": "2019-06-14T17:40:10.984037Z"
    }
   },
   "outputs": [],
   "source": [
    "gs_gbm = GridSearchCV(\n",
    "    estimator=pipe_gbm,\n",
    "    param_grid=grid_params_gbm,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10,\n",
    "    n_jobs=jobs\n",
    ")\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=grid_params_lr,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10\n",
    ") \n",
    "\n",
    "gs_lr_pca = GridSearchCV(\n",
    "    estimator=pipe_lr_pca,\n",
    "    param_grid=grid_params_lr,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=grid_params_rf,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10, \n",
    "    n_jobs=jobs\n",
    ")\n",
    "\n",
    "gs_rf_pca = GridSearchCV(\n",
    "    estimator=pipe_rf_pca,\n",
    "    param_grid=grid_params_rf,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=10, \n",
    "    n_jobs=jobs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:42:49.002595Z",
     "start_time": "2019-06-14T17:40:10.990693Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Gradient Boosted Machine\n",
      "Best params: {'clf__learning_rate': 0.1, 'clf__max_depth': 8, 'clf__max_features': 'log2', 'clf__n_estimators': 100}\n",
      "Best training accuracy: 0.929\n",
      "Test set accuracy score for best params: 0.730 \n",
      "ROC_AUC score for best params: 0.709\n",
      "\n",
      "Estimator: Logistic Regression\n"
     ]
    }
   ],
   "source": [
    "grids = [\n",
    "    gs_gbm, \n",
    "    gs_lr, \n",
    "    gs_lr_pca, \n",
    "    gs_rf, \n",
    "    gs_rf_pca\n",
    "]\n",
    "\n",
    "grid_dict = {\n",
    "    0: \"Gradient Boosted Machine\",\n",
    "    1: \"Logistic Regression\", \n",
    "    2: \"Logistic Regression w/PCA\", \n",
    "    3: \"Random Forest\", \n",
    "    4: \"Random Forest w/PCA\", \n",
    "}\n",
    "\n",
    "# Fit the grid search objects\n",
    "print(\"Performing model optimizations...\")\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print(\"\\nEstimator: %s\" % grid_dict[idx])\n",
    "\n",
    "    gs.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best params: %s\" % gs.best_params_)\n",
    "    print(\"Best training accuracy: %.3f\" % gs.best_score_)\n",
    "\n",
    "    y_pred = gs.predict(X_test)\n",
    "    y_prob = gs.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    print(\"Test set accuracy score for best params: %.3f \" % accuracy_score(y_test, y_pred))\n",
    "    print(\"ROC_AUC score for best params: %.3f\" % roc_auc_score(y_test, y_prob))\n",
    "\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print(\"\\nClassifier with best test set accuracy: %s\" % grid_dict[best_clf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:42:49.003641Z",
     "start_time": "2019-06-14T17:40:00.937Z"
    }
   },
   "outputs": [],
   "source": [
    "color_dict = {\n",
    "    0: \"blue\",\n",
    "    1: \"red\", \n",
    "    2: \"green\", \n",
    "    3: \"black\", \n",
    "    4: \"purple\", \n",
    "}\n",
    "plt.figure(figsize=(20, 15))\n",
    "for idx, gs in enumerate(grids):\n",
    "    probs = gs.predict_proba(X_test)\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = metrics.roc_curve(y_test, preds)\n",
    "    roc_auc = metrics.auc(fpr, tpr)\n",
    "    plt.title(\"Receiver Operating Characteristic\")\n",
    "    plt.plot(\n",
    "        fpr, \n",
    "        tpr, \n",
    "        color=color_dict[idx], \n",
    "        label = \"\"%s AUC = %0.2f\" % (grid_dict[idx], roc_auc)\n",
    "    )\n",
    "    plt.legend(loc = \"lower right\")\n",
    "    plt.plot([0, 1], [0, 1], \"r--\"\")\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:42:49.005370Z",
     "start_time": "2019-06-14T17:40:00.939Z"
    }
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\").fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.DataFrame(\n",
    "    rf.feature_importances_,\n",
    "    index = X_train.columns,\n",
    "    columns=[\"importance\"]\n",
    ").sort_values(\n",
    "    \"importance\", \n",
    "    ascending=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:42:49.006234Z",
     "start_time": "2019-06-14T17:40:00.942Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.xticks(rotation=90)\n",
    "plt.bar(feature_importances.index, feature_importances[\"importance\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation\n",
    "- Check if there is data leakage?\n",
    "- A sudden jump to 90% accuracy seems dubious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:42:49.007359Z",
     "start_time": "2019-06-14T17:40:00.945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=42)\n",
    "cross_val_score(\n",
    "    pipe_rf, \n",
    "    X_train, \n",
    "    y_train, \n",
    "    cv=cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
