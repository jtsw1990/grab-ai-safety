{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only read in relevant X_train dataset\n",
    "\n",
    "- Feature extraction only requries X_train to prevent any leakage\n",
    "- Also, to extract processes into a few functions for reusability\n",
    "- General process will be:\n",
    "    - Read in raw feature data\n",
    "    - Remove outliers\n",
    "    - Extract features\n",
    "    - Perform resampling if required\n",
    "    - Export for model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:38:55.345948Z",
     "start_time": "2019-06-14T17:38:54.644120Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import dill as pickle\n",
    "\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:38:57.363167Z",
     "start_time": "2019-06-14T17:38:55.349187Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"../../grab-ai-safety-data/X_train.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing column names\n",
    "- Making all columns lower cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:38:57.368200Z",
     "start_time": "2019-06-14T17:38:57.365007Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_columns(feature_matrix):\n",
    "    feature_matrix.columns = [\n",
    "        x.lower() for x in feature_matrix.columns\n",
    "    ]\n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers\n",
    "- Change column names to all lower case\n",
    "- Some initial analysis reveals some ridiculous outliers in the data\n",
    "    - Some bookings have a max second (or duration) of 47 years\n",
    "    - Also, use this chance to perform some truncating of the data for each booking\n",
    "    - Reason being, not every reading will be useful. Try getting rid of the ends.\n",
    "- Pandas depreciation does not allow multiple lambda functions in aggregate function. Separately define percentiles\n",
    "- 148 max m/s is ridiculous, set threshold at 45\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:38:57.376858Z",
     "start_time": "2019-06-14T17:38:57.370703Z"
    }
   },
   "outputs": [],
   "source": [
    "def min_boundary(x):\n",
    "    return np.percentile(x, q=5)\n",
    "def max_boundary(x):\n",
    "    return np.percentile(x, q=95)\n",
    "def min_speed(x):\n",
    "    return 0\n",
    "def max_speed(x):\n",
    "    return 45\n",
    "\n",
    "\n",
    "def create_windows(df):\n",
    "    ''' Function takes in a 2D feature matrix and creates a duration\n",
    "    boundary for each bookingid based on a pre-specified percentile\n",
    "    \n",
    "    Args:\n",
    "    A 2D pandas dataframe\n",
    "    \n",
    "    Returns:\n",
    "    Filtered feature matrix where duration is within the bounds\n",
    "    of the min and max duration percentiles\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    df_original = df.copy()\n",
    "    bounds_df = df.groupby(\"bookingid\").agg(\n",
    "        {\n",
    "            \"second\" : [\n",
    "                min_boundary,\n",
    "                max_boundary\n",
    "            ],\n",
    "            \"speed\" : [\n",
    "                min_speed,\n",
    "                max_speed\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    bounds_df.columns = [\n",
    "        \"_\".join(x) if x[0] != \"label\" else x[0] for x in bounds_df.columns.ravel()\n",
    "    ]\n",
    "    \n",
    "    df_filtered = pd.merge(\n",
    "        df, \n",
    "        bounds_df, \n",
    "        how=\"left\", \n",
    "        on=\"bookingid\"\n",
    "    )\n",
    "    \n",
    "    df_filtered = df_filtered.loc[\n",
    "        (df_filtered[\"second\"] >= df_filtered[\"second_min_boundary\"]) &\\\n",
    "        (df_filtered[\"second\"] <= df_filtered[\"second_max_boundary\"]) &\\\n",
    "        (df_filtered[\"speed\"] >= df_filtered[\"speed_min_speed\"]) &\\\n",
    "        (df_filtered[\"speed\"] <= df_filtered[\"speed_max_speed\"]),\n",
    "        list(df_original.columns)\n",
    "    ]\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting features from raw data\n",
    "- Combined acceleration and gyro terms using simple Pythagorean formula\n",
    "    - Both acceleration and gyro may not be relevant in space\n",
    "    - Data is probably manually labeled\n",
    "- Change in bearing per second\n",
    "- Arbitrary score: Total bearing change / distance per trip as an indication of how winding the route is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:38:57.387312Z",
     "start_time": "2019-06-14T17:38:57.378893Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_features(df):\n",
    "    ''' Function takes in a 2D panadas dataframe and extracts\n",
    "    certain features\n",
    "    \n",
    "    Args:\n",
    "    A 2D pandas dataframe\n",
    "    \n",
    "    Returns:\n",
    "    A grouped version of the feature matrix by booking id with extra feature\n",
    "    columns deemed to be relevant for predictive modelling purposes\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Acceleration and gyro features\n",
    "    df[\"acceleration\"] = np.sqrt(\n",
    "        (df[\"acceleration_x\"] ** 2) + (df[\"acceleration_y\"] ** 2) + (df[\"acceleration_z\"] ** 2)\n",
    "    )\n",
    "\n",
    "    df[\"gyro\"] = np.sqrt(\n",
    "        (df[\"gyro_x\"] ** 2) + (df[\"gyro_y\"] ** 2) + (df[\"gyro_z\"] ** 2)\n",
    "    )\n",
    "    \n",
    "    # Differenced series to get a measure of distance and a change in bearing\n",
    "    mask = df[\"bookingid\"] != df[\"bookingid\"].shift(1)\n",
    "    df[\"duration_of_entry\"] = df[\"second\"].diff().fillna(0)\n",
    "    df[\"change_in_bearing\"] = np.abs(df[\"bearing\"].diff().fillna(0))\n",
    "    df[\"change_in_acceleration\"] = np.abs(df[\"acceleration\"]).diff().fillna(0)\n",
    "    df[\"change_in_gyro\"] = np.abs(df[\"gyro\"]).diff().fillna(0)\n",
    "    df.loc[ mask, [\"duration_of_entry\", \"change_in_bearing\"]] = 0\n",
    "    \n",
    "    df[\"distance_covered\"] = df[\"speed\"] * df[\"duration_of_entry\"]\n",
    "    df[\"change_in_bearing_per_sec\"] = df[\"change_in_bearing\"] / df[\"duration_of_entry\"]\n",
    "    \n",
    "    # Aggregating booking IDs \n",
    "    df_grouped = df.groupby(\"bookingid\").agg(\n",
    "        {\n",
    "            \"second\" : [np.max],\n",
    "            \"distance_covered\" : [np.sum],\n",
    "            \"acceleration\" : [np.max, np.min, np.mean, lambda x: np.percentile(x, q=50), np.std],\n",
    "            \"gyro\" : [np.max, np.mean, lambda x: np.percentile(x, q=50), np.std],\n",
    "            \"change_in_acceleration\" : [np.max],\n",
    "            \"change_in_gyro\" : [np.max],\n",
    "            \"speed\" : [np.max, np.mean, lambda x: np.percentile(x, q=50), np.std],\n",
    "            \"change_in_bearing_per_sec\" : [np.max, np.std],\n",
    "            \"change_in_bearing\" : [np.sum]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    df_grouped.columns = [\"_\".join(x) if x[0] != \"label\" else x[0] for x in df_grouped.columns.ravel()]\n",
    "    df_grouped[\"change_in_bearing_per_m\"] = (\n",
    "        df_grouped[\"change_in_bearing_sum\"] / df_grouped[\"distance_covered_sum\"]\n",
    "    ).fillna(0)\n",
    "    return df_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:39:24.907951Z",
     "start_time": "2019-06-14T17:38:57.389314Z"
    }
   },
   "outputs": [],
   "source": [
    "df_grouped = (\n",
    "    df.pipe(\n",
    "        clean_columns\n",
    "    ).pipe(\n",
    "        create_windows\n",
    "    ).pipe(\n",
    "        extract_features\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-14T17:39:24.925278Z",
     "start_time": "2019-06-14T17:39:24.909943Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../../grab-ai-safety-data/X_train_transformed.pickle\", 'wb') as f:\n",
    "    pickle.dump(df_grouped, f)\n",
    "    \n",
    "with open(\"../outputs/clean_columns.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(clean_columns, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"../outputs/create_windows.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(create_windows, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"../outputs/extract_features.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(extract_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"../outputs/min_boundary.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(min_boundary, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(\"../outputs/max_boundary.pickle\", \"wb\") as handle:\n",
    "    pickle.dump(max_boundary, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
