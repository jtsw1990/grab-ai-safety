{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "\n",
    "- The main reason for this is that GBMs has no good way to introduce sample weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T13:29:12.486258Z",
     "start_time": "2019-06-10T13:29:11.481282Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data grouped by bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T13:29:12.495740Z",
     "start_time": "2019-06-10T13:29:12.488356Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"outputs/df_grouped.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and testing\n",
    "\n",
    "- Try different testing and training sizes although not expecting much of a difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T13:29:12.503630Z",
     "start_time": "2019-06-10T13:29:12.497893Z"
    }
   },
   "outputs": [],
   "source": [
    "features = df.iloc[:, :-1]\n",
    "response = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-10T13:29:12.512754Z",
     "start_time": "2019-06-10T13:29:12.505252Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features,\n",
    "    response,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model pipeline\n",
    "\n",
    "- Using standard scaler seems to work the best.\n",
    "- Pipelines\n",
    "    - Logistic Regression (PCA)\n",
    "    - Random Forests (PCA)\n",
    "    - Support Vector Machine (PCA)\n",
    "    - Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-10T13:29:11.478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing model optimizations...\n",
      "\n",
      "Estimator: Logistic Regression\n",
      "Best params: {'clf__C': 1.0, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "Best training accuracy: 0.762\n",
      "Test set accuracy score for best params: 0.759 \n",
      "\n",
      "Estimator: Logistic Regression w/PCA\n",
      "Best params: {'clf__C': 0.5, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "Best training accuracy: 0.756\n",
      "Test set accuracy score for best params: 0.752 \n",
      "\n",
      "Estimator: Random Forest\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_lr_pca = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", LogisticRegression(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_rf = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", RandomForestClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_rf_pca = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", RandomForestClassifier(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_svm = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"clf\", svm.SVC(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe_svm_pca = Pipeline(\n",
    "    [\n",
    "        (\"scl\", StandardScaler()),\n",
    "        (\"pca\", PCA(n_components=2)),\n",
    "        (\"clf\", svm.SVC(random_state=42))\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Set grid search params\n",
    "param_range = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "param_range_fl = [1.0, 0.5, 0.1]\n",
    "\n",
    "grid_params_lr = [\n",
    "    {\n",
    "        \"clf__penalty\" : [\"l1\", \"l2\"],\n",
    "        \"clf__C\" : param_range_fl,\n",
    "        \"clf__solver\" : [\"liblinear\"]\n",
    "    }\n",
    "] \n",
    "\n",
    "grid_params_rf = [\n",
    "    {\n",
    "        \"clf__criterion\" : [\"gini\", \"entropy\"],\n",
    "        \"clf__min_samples_leaf\" : param_range,\n",
    "        \"clf__max_depth\" : param_range,\n",
    "        \"clf__min_samples_split\" : param_range[1:]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_params_svm = [\n",
    "    {\n",
    "        \"clf__kernel\" : [\"linear\", \"rbf\"], \n",
    "        \"clf__C\": param_range\n",
    "    }\n",
    "]\n",
    "\n",
    "# Construct grid searches\n",
    "jobs = -1\n",
    "\n",
    "gs_lr = GridSearchCV(\n",
    "    estimator=pipe_lr,\n",
    "    param_grid=grid_params_lr,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=10\n",
    ") \n",
    "\n",
    "gs_lr_pca = GridSearchCV(\n",
    "    estimator=pipe_lr_pca,\n",
    "    param_grid=grid_params_lr,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=10\n",
    ")\n",
    "\n",
    "\n",
    "gs_rf = GridSearchCV(\n",
    "    estimator=pipe_rf,\n",
    "    param_grid=grid_params_rf,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=10, \n",
    "    n_jobs=jobs\n",
    ")\n",
    "\n",
    "gs_rf_pca = GridSearchCV(\n",
    "    estimator=pipe_rf_pca,\n",
    "    param_grid=grid_params_rf,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=10, \n",
    "    n_jobs=jobs\n",
    ")\n",
    "\n",
    "gs_svm = GridSearchCV(\n",
    "    estimator=pipe_svm,\n",
    "    param_grid=grid_params_svm,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=10,\n",
    "    n_jobs=jobs\n",
    ")\n",
    "\n",
    "gs_svm_pca = GridSearchCV(\n",
    "    estimator=pipe_svm_pca,\n",
    "    param_grid=grid_params_svm,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=10,\n",
    "    n_jobs=jobs\n",
    ")\n",
    "\n",
    "# List of pipelines for ease of iteration\n",
    "grids = [gs_lr, gs_lr_pca, gs_rf, gs_rf_pca, gs_svm, gs_svm_pca]\n",
    "\n",
    "# Dictionary of pipelines and classifier types for ease of reference\n",
    "grid_dict = {\n",
    "    0: 'Logistic Regression', \n",
    "    1: 'Logistic Regression w/PCA', \n",
    "    2: 'Random Forest', \n",
    "    3: 'Random Forest w/PCA', \n",
    "    4: 'Support Vector Machine', \n",
    "    5: 'Support Vector Machine w/PCA'\n",
    "}\n",
    "\n",
    "# Fit the grid search objects\n",
    "print('Performing model optimizations...')\n",
    "best_acc = 0.0\n",
    "best_clf = 0\n",
    "best_gs = ''\n",
    "for idx, gs in enumerate(grids):\n",
    "    print('\\nEstimator: %s' % grid_dict[idx])\t\n",
    "    # Fit grid search\t\n",
    "    gs.fit(X_train, y_train)\n",
    "    # Best params\n",
    "    print('Best params: %s' % gs.best_params_)\n",
    "    # Best training data accuracy\n",
    "    print('Best training accuracy: %.3f' % gs.best_score_)\n",
    "    # Predict on test data with best params\n",
    "    y_pred = gs.predict(X_test)\n",
    "    # Test data accuracy of model with best params\n",
    "    print('Test set accuracy score for best params: %.3f ' % accuracy_score(y_test, y_pred))\n",
    "    # Track best (highest test accuracy) model\n",
    "    if accuracy_score(y_test, y_pred) > best_acc:\n",
    "        best_acc = accuracy_score(y_test, y_pred)\n",
    "        best_gs = gs\n",
    "        best_clf = idx\n",
    "print('\\nClassifier with best test set accuracy: %s' % grid_dict[best_clf])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
